{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "from os.path import exists\n",
    "\n",
    "\n",
    "# TODO: allow for loading all three jet types together\n",
    "\n",
    "\n",
    "class JetNet(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch ``torch.utils.data.Dataset`` class for the JetNet dataset.\n",
    "\n",
    "    Features, in order: ``[eta, phi, pt, mask]``.\n",
    "\n",
    "    Will produce an iteratable of either the dataset alone, of shape\n",
    "    ``[num_jets, num_particles, num_features]``, or a tuple of the dataset and jet-level features\n",
    "    of each jet. Currently only the number of (non-zero-padded) particles per jet is available as\n",
    "    a jet feature.\n",
    "\n",
    "    If pt or hdf5 files are not found in the ``data_dir`` directory then:\n",
    "    If ``num_particles <= 30``, JetNet is downloaded from https://zenodo.org/record/6302454;\n",
    "    Else, JetNet150 is downloaded from https://zenodo.org/record/6302240\n",
    "\n",
    "    Args:\n",
    "        jet_type (str): 'g' (gluon), 't' (top quarks), or 'q' (light quarks).\n",
    "        data_dir (str): directory which contains (or in which to download) dataset.\n",
    "          Defaults to \"./\" i.e. the working directory.\n",
    "        download (bool): download the dataset, even if the hdf5 file exists already.\n",
    "          Defaults to False.\n",
    "        num_particles (int): number of particles to use, has to be less than or equal to 150.\n",
    "          Defaults to 30.\n",
    "        normalize (bool): normalize features for training or not, using parameters defined below.\n",
    "          Defaults to True.\n",
    "        feature_norms (Union[float, List[float]]): max value to scale each feature to.\n",
    "          Can either be a single float for all features, or a list of length ``num_features``.\n",
    "          Defaults to 1.0.\n",
    "        feature_shifts (Union[float, List[float]]): after scaling, value to shift feature by.\n",
    "          Can either be a single float for all features, or a list of length ``num_features``.\n",
    "          Defaults to 0.0.\n",
    "        use_mask (bool): Defaults to True.\n",
    "        train (bool): whether for training or testing. Defaults to True.\n",
    "        train_fraction (float): fraction of data to use as training - rest is for testing.\n",
    "          Defaults to 0.7.\n",
    "        num_pad_particles (int): how many out of ``num_particles`` should be zero-padded.\n",
    "          Defaults to 0.\n",
    "        use_num_particles_jet_feature (bool): Store the # of particles in each jet as a\n",
    "          jet-level feature. *Only works if using mask* i.e. if ``use_mask=True``. Defaults to True.\n",
    "        noise_padding (bool): instead of 0s, pad extra particles with Gaussian noise.\n",
    "          Only works if using mask. Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    _num_non_mask_features = 3\n",
    "\n",
    "    # normalization used for ParticleNet training\n",
    "    _fpnd_feature_maxes = [1.6211985349655151, 0.520724892616272, 0.8934717178344727, 1.0]\n",
    "    _fpnd_feature_norms = 1.0\n",
    "    _fpnd_feature_shifts = [0.0, 0.0, -0.5, 0.0]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        jet_type: str,\n",
    "        data_dir: str = \"./\",\n",
    "        download: bool = False,\n",
    "        num_particles: int = 30,\n",
    "        normalize: bool = True,\n",
    "        feature_norms: List[float] = [1.0, 1.0, 1.0, 1.0],\n",
    "        feature_shifts: List[float] = [0.0, 0.0, -0.5, -0.5],\n",
    "        use_mask: bool = True,\n",
    "        num_pad_particles: int = 0,\n",
    "        use_num_particles_jet_feature: bool = True,\n",
    "        noise_padding: bool = False,\n",
    "    ):\n",
    "\n",
    "        assert jet_type in [\"top\", \"qcd\"], \"Invalid jet type\"\n",
    "        dataset_type=input(\"Enter test for testing, train for training and val for validation\"),\n",
    "        if dataset_type==\"train\": \n",
    "         data_fraction = ' '\n",
    "        \n",
    "        elif dataset_type=='test':\n",
    "              data_fraction = ' '\n",
    "        else:\n",
    "            data_fraction = ' '\n",
    "        \n",
    "        self.feature_norms = feature_norms\n",
    "        self.feature_shifts = feature_shifts\n",
    "        self.use_mask = use_mask\n",
    "        # in the future there'll be more jet features such as jet pT and eta\n",
    "        self.use_jet_features = use_num_particles_jet_feature and self.use_mask\n",
    "\n",
    "\n",
    "        # Use JetNet150 if ``num_particles`` > 30\n",
    "        pt_file = f\"{data_dir}/{jet_type}{'200'}.pt\"\n",
    "\n",
    "        if not exists(pt_file) or download:\n",
    "            self.download_and_convert_to_pt(data_dir, jet_type)\n",
    "\n",
    "        logging.info(\"Loading dataset\")\n",
    "        dataset = self.load_dataset(pt_file, num_particles, num_pad_particles, use_mask)\n",
    "        self.num_particles = num_particles if num_particles > 0 else dataset.shape[1]\n",
    "\n",
    "        if self.use_jet_features:\n",
    "            jet_features = self.get_jet_features(dataset, use_num_particles_jet_feature)\n",
    "\n",
    "        logging.info(f\"Loaded dataset {dataset.shape = }\")\n",
    "     \n",
    "        tcut = int(len(dataset) * train_fraction)\n",
    "\n",
    "        self.data = dataset[:tcut] if train else dataset[tcut:]\n",
    "        if self.use_jet_features:\n",
    "            self.jet_features = jet_features[:tcut] if train else jet_features[tcut:]\n",
    "\n",
    "        logging.info(\"Dataset processed\")\n",
    "\n",
    "    def download_and_convert_to_pt(self, data_dir: str, jet_type: str):\n",
    "        \"\"\"\n",
    "        Download jet dataset and convert and save to pytorch tensor.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): directory in which to save file.\n",
    "            jet_type (str): jet type to download, out of ``['g', 't', 'q']``.\n",
    "            use_150 (bool): download JetNet150 or JetNet. Defaults to False.\n",
    "\n",
    "        \"\"\"\n",
    "        import os\n",
    "\n",
    "        os.system(f\"mkdir -p {data_dir}\")\n",
    "        hdf5_file = f\"{data_dir}/{jet_type}{'200'}.hdf5\"\n",
    "\n",
    "        if not exists(hdf5_file):\n",
    "            logging.info(f\"Downloading {jet_type} jets hdf5\")\n",
    "            self.download(jet_type, hdf5_file)\n",
    "\n",
    "        logging.info(f\"Converting {jet_type} jets hdf5 to pt\")\n",
    "        self.hdf5_to_pt(data_dir, jet_type, hdf5_file)\n",
    "\n",
    "    def download(self, jet_type: str, hdf5_file: str):\n",
    "        \"\"\"\n",
    "        Downloads the ``jet_type`` jet hdf5 from Zenodo and saves it as ``hdf5_file``.\n",
    "\n",
    "        Args:\n",
    "            jet_type (str): jet type to download, out of ``['g', 't', 'q']``.\n",
    "            hdf5_file (str): path to save hdf5 file.\n",
    "            use_150 (bool): download JetNet150 or JetNet. Defaults to False.\n",
    "\n",
    "        \"\"\"\n",
    "        import requests\n",
    "        import sys\n",
    "\n",
    "        record_id = 2603256 \n",
    "        records_url = f\"https://zenodo.org/api/records/{record_id}\"\n",
    "        r = requests.get(records_url).json()\n",
    "        key = f\"{jet_type}{'200' }.hdf5\"\n",
    "\n",
    "        # finding the url for the particular jet type dataset\n",
    "        file_url = next(item for item in r[\"files\"] if item[\"key\"] == key)[\"links\"][\"self\"]\n",
    "        logging.info(f\"{file_url = }\")\n",
    "\n",
    "        # modified from https://sumit-ghosh.com/articles/python-download-progress-bar/\n",
    "        with open(hdf5_file, \"wb\") as f:\n",
    "            response = requests.get(file_url, stream=True)\n",
    "            total = response.headers.get(\"content-length\")\n",
    "\n",
    "            if total is None:\n",
    "                f.write(response.content)\n",
    "            else:\n",
    "                downloaded = 0\n",
    "                total = int(total)\n",
    "\n",
    "                print(\"Downloading dataset\")\n",
    "                for data in response.iter_content(chunk_size=max(int(total / 1000), 1024 * 1024)):\n",
    "                    downloaded += len(data)\n",
    "                    f.write(data)\n",
    "                    done = int(50 * downloaded / total)\n",
    "                    sys.stdout.write(\n",
    "                        \"\\r[{}{}] {:.0f}%\".format(\n",
    "                            \"â–ˆ\" * done, \".\" * (50 - done), float(downloaded / total) * 100\n",
    "                        )\n",
    "                    )\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "        sys.stdout.write(\"\\n\")\n",
    "\n",
    "    def hdf5_to_pt(self, data_dir: str, jet_type: str, hdf5_file: str):\n",
    "        \"\"\"\n",
    "        Converts and saves downloaded hdf5 file to pytorch tensor.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): directory in which to save file.\n",
    "            jet_type (str): jet type to download, out of ``['g', 't', 'q']``.\n",
    "            hdf5_file (str): path to hdf5 file.\n",
    "            use_150 (bool): download JetNet150 or JetNet. Defaults to False.\n",
    "\n",
    "        \"\"\"\n",
    "        import h5py\n",
    "\n",
    "        pt_file = f\"{data_dir}/{jet_type}{'200'}.pt\"\n",
    "\n",
    "        with h5py.File(hdf5_file, \"r\") as f:\n",
    "            torch.save(Tensor(np.array(f[\"particle_features\"])), pt_file)\n",
    "\n",
    "    def load_dataset(\n",
    "        self, pt_file: str, num_particles: int, num_pad_particles: int = 0, use_mask: bool = True\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Load the dataset, optionally padding the particles.\n",
    "\n",
    "        Args:\n",
    "            pt_file (str): path to dataset .pt file.\n",
    "            num_particles (int): number of particles per jet to load\n",
    "              (has to be less than the number per jet in the dataset).\n",
    "            num_pad_particles (int): out of ``num_particles`` how many are to be zero-padded.\n",
    "              Defaults to 0.\n",
    "            use_mask (bool): keep or remove the mask feature. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: dataset tensor of shape ``[num_jets, num_particles, num_features]``.\n",
    "\n",
    "        \"\"\"\n",
    "        dataset = torch.load(pt_file).float()\n",
    "\n",
    "        # only retain up to ``num_particles``,\n",
    "        # subtracting ``num_pad_particles`` since they will be padded below\n",
    "        if 0 < num_particles - num_pad_particles < dataset.shape[1]:\n",
    "            dataset = dataset[:, : num_particles - num_pad_particles, :]\n",
    "\n",
    "        # pad with ``num_pad_particles`` particles\n",
    "        if num_pad_particles > 0:\n",
    "            dataset = torch.nn.functional.pad(dataset, (0, 0, 0, num_pad_particles), \"constant\", 0)\n",
    "\n",
    "        if not use_mask:\n",
    "            # remove mask feature from dataset if not needed\n",
    "            dataset = dataset[:, :, : self._num_non_mask_features]\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def get_jet_features(self, dataset: Tensor, use_num_particles_jet_feature: bool) -> Tensor:\n",
    "        \"\"\"\n",
    "        Returns jet-level features. `Will be expanded to include jet pT and eta.`\n",
    "\n",
    "        Args:\n",
    "            dataset (Tensor):  dataset tensor of shape [N, num_particles, num_features],\n",
    "              where the last feature is the mask.\n",
    "            use_num_particles_jet_feature (bool): `Currently does nothing,\n",
    "              in the future such bools will specify which jet features to use`.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: jet features tensor of shape [N, num_jet_features].\n",
    "\n",
    "        \"\"\"\n",
    "        jet_num_particles = (torch.sum(dataset[:, :, -1], dim=1) / self.num_particles).unsqueeze(1)\n",
    "        logging.debug(\"{num_particles = }\")\n",
    "        return jet_num_particles\n",
    "\n",
    "    @classmethod\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.jet_features[idx] if self.use_jet_features else self.data[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0fe7b544b91fdae879a8427963a6056d0fd4faa9d244d4855e28ddfc76a93b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
